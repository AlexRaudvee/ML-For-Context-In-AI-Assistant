{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWWhvyR44BJu"
      },
      "source": [
        "# Google Colab for training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up the files inside colab\n",
        "\n",
        "Make sure you have a `ML-For-Context-In-AI-Assistant-colab.zip` in your google disk before funning the cell bellow"
      ],
      "metadata": {
        "id": "Ea6hP1DcL7Oj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTNkYvMd4BJv",
        "outputId": "3b0632b1-9f7c-4623-e6db-af769d8ed0ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the zip file in your mounted Drive\n",
        "zip_path = '/content/drive/MyDrive/ML-For-Context-In-AI-Assistant-colab.zip'\n",
        "\n",
        "# Destination directory\n",
        "extract_to = '/content/'\n",
        "\n",
        "# Make sure the zip exists\n",
        "if not os.path.isfile(zip_path):\n",
        "    raise FileNotFoundError(f\"Could not find zip file at {zip_path}\")\n",
        "\n",
        "# Unzip\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# source and destination\n",
        "src_dir = '/content/ML-For-Context-In-AI-Assistant-colab'\n",
        "dst_dir = '/content'\n",
        "\n",
        "# sanity check\n",
        "if not os.path.isdir(src_dir):\n",
        "    raise FileNotFoundError(f\"{src_dir} does not exist\")\n",
        "\n",
        "# move each file/subfolder\n",
        "for name in os.listdir(src_dir):\n",
        "    src_path = os.path.join(src_dir, name)\n",
        "    dst_path = os.path.join(dst_dir, name)\n",
        "\n",
        "    if os.path.exists(dst_path):\n",
        "        print(f\"Warning: {dst_path} already exists, overwriting\")\n",
        "        if os.path.isdir(dst_path):\n",
        "            shutil.rmtree(dst_path)\n",
        "        else:\n",
        "            os.remove(dst_path)\n",
        "    shutil.move(src_path, dst_path)\n",
        "\n",
        "# remove the empty folder\n",
        "os.rmdir(src_dir)\n",
        "\n",
        "### Helper Funcs:\n",
        "\n",
        "def zip_folder(folder_path: str, output_path: str) -> None:\n",
        "    \"\"\"\n",
        "    Recursively zip the contents of folder_path into a .zip file at output_path.\n",
        "\n",
        "    :param folder_path: Path to the folder to compress.\n",
        "    :param output_path: Path (including filename) for the output .zip file.\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(output_path, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                # Preserve folder structure in the archive\n",
        "                arcname = os.path.relpath(file_path, start=folder_path)\n",
        "                zipf.write(file_path, arcname)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install the requirements\n",
        "\n",
        "If the message of restarting the kernel appears ignore it as i did (otherwise, do your own magic) :]"
      ],
      "metadata": {
        "id": "HEUhRATsMHHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Prepare: upgrade pip tooling & install uv ---\n",
        "!python -m pip install -q -U pip wheel setuptools uv\n",
        "\n",
        "# --- Install PyTorch first (GPU if available, else CPU) ---\n",
        "import subprocess, os\n",
        "has_gpu = \"NVIDIA\" in subprocess.getoutput(\"nvidia-smi -L 2>/dev/null\")\n",
        "index = \"https://download.pytorch.org/whl/cu121\" if has_gpu else \"https://download.pytorch.org/whl/cpu\"\n",
        "print(\"GPU:\", has_gpu, \"| Torch index:\", index)\n",
        "\n",
        "# Pin torch first; change version if you really need 2.8.0\n",
        "!pip install -q -U --index-url {index} torch==2.8.0\n",
        "\n",
        "# --- Use uv to install everything else from your file (faster resolver/downloads) ---\n",
        "# If your file is named differently, adjust the path:\n",
        "req_path = \"/content/requirements.txt\"  # put your pasted contents here or upload_file\n",
        "filtered = []\n",
        "for line in open(req_path):\n",
        "    if line.strip().startswith(\"torch==\"):  # we already installed torch\n",
        "        continue\n",
        "    if line.strip().startswith(\"ipython==\"):  # we already installed torch\n",
        "        continue\n",
        "    if line.strip().startswith(\"ipykernel==\"):  # we already installed torch\n",
        "        continue\n",
        "    if line.strip().startswith(\"tornado==\"):  # we already installed torch\n",
        "        continue\n",
        "    if line.strip().startswith(\"prompt_toolkit==\"):  # we already installed torch\n",
        "        continue\n",
        "    if line.strip().startswith(\"pyzmq==\"):  # we already installed torch\n",
        "        continue\n",
        "\n",
        "    filtered.append(line)\n",
        "open(\"/content/requirements_no_torch.txt\",\"w\").write(\"\".join(filtered))\n",
        "\n",
        "# Install into the current environment (system Python inside Colab)\n",
        "!pip install -r requirements_no_torch.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GVSlNIjQ5Pfb",
        "outputId": "d374c9b4-1131-4186-8bcb-612f55419253"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mGPU: False | Torch index: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: accelerate==1.10.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 1)) (1.10.1)\n",
            "Requirement already satisfied: aiohappyeyeballs==2.6.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: aiohttp==3.13.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 3)) (3.13.0)\n",
            "Requirement already satisfied: aiosignal==1.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: annotated-types==0.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: anyio==4.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 6)) (4.11.0)\n",
            "Collecting asttokens==3.0.0 (from -r requirements_no_torch.txt (line 7))\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: attrs==25.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 8)) (25.4.0)\n",
            "Requirement already satisfied: certifi==2025.10.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 9)) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer==3.4.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 10)) (3.4.3)\n",
            "Requirement already satisfied: click==8.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 11)) (8.3.0)\n",
            "Collecting comm==0.2.3 (from -r requirements_no_torch.txt (line 12))\n",
            "  Downloading comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: contourpy==1.3.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 13)) (1.3.3)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 14)) (0.12.1)\n",
            "Collecting datasets==3.6.0 (from -r requirements_no_torch.txt (line 15))\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting debugpy==1.8.17 (from -r requirements_no_torch.txt (line 16))\n",
            "  Downloading debugpy-1.8.17-cp312-cp312-manylinux_2_34_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting decorator==5.2.1 (from -r requirements_no_torch.txt (line 17))\n",
            "  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: dill==0.3.8 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 18)) (0.3.8)\n",
            "Collecting eval_type_backport==0.2.2 (from -r requirements_no_torch.txt (line 19))\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting executing==2.2.1 (from -r requirements_no_torch.txt (line 20))\n",
            "  Downloading executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: fastapi==0.118.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 21)) (0.118.2)\n",
            "Requirement already satisfied: filelock==3.20.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 22)) (3.20.0)\n",
            "Requirement already satisfied: fonttools==4.60.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 23)) (4.60.1)\n",
            "Requirement already satisfied: frozenlist==1.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 24)) (1.8.0)\n",
            "Requirement already satisfied: fsspec==2025.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 25)) (2025.3.0)\n",
            "Requirement already satisfied: grpcio==1.75.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 26)) (1.75.1)\n",
            "Requirement already satisfied: h11==0.16.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 27)) (0.16.0)\n",
            "Requirement already satisfied: h2==4.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 28)) (4.3.0)\n",
            "Requirement already satisfied: hf-xet==1.1.10 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 29)) (1.1.10)\n",
            "Requirement already satisfied: hpack==4.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 30)) (4.1.0)\n",
            "Requirement already satisfied: httpcore==1.0.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 31)) (1.0.9)\n",
            "Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 32)) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub==0.35.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 33)) (0.35.3)\n",
            "Requirement already satisfied: hyperframe==6.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 34)) (6.1.0)\n",
            "Requirement already satisfied: idna==3.10 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 35)) (3.10)\n",
            "Collecting ipython_pygments_lexers==1.1.1 (from -r requirements_no_torch.txt (line 36))\n",
            "  Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting jedi==0.19.2 (from -r requirements_no_torch.txt (line 37))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: Jinja2==3.1.6 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 38)) (3.1.6)\n",
            "Requirement already satisfied: joblib==1.5.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 39)) (1.5.2)\n",
            "Collecting jupyter_client==8.6.3 (from -r requirements_no_torch.txt (line 40))\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: jupyter_core==5.8.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 41)) (5.8.1)\n",
            "Requirement already satisfied: kiwisolver==1.4.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 42)) (1.4.9)\n",
            "Collecting lightning-utilities==0.15.2 (from -r requirements_no_torch.txt (line 43))\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: markdown-it-py==4.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 44)) (4.0.0)\n",
            "Requirement already satisfied: MarkupSafe==3.0.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 45)) (3.0.3)\n",
            "Collecting matplotlib==3.10.7 (from -r requirements_no_torch.txt (line 46))\n",
            "  Downloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.7 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 47)) (0.1.7)\n",
            "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 48)) (0.1.2)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 49)) (1.3.0)\n",
            "Collecting mteb==1.39.7 (from -r requirements_no_torch.txt (line 50))\n",
            "  Downloading mteb-1.39.7-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: multidict==6.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 51)) (6.7.0)\n",
            "Requirement already satisfied: multiprocess==0.70.16 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 52)) (0.70.16)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 53)) (1.6.0)\n",
            "Requirement already satisfied: networkx==3.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 54)) (3.5)\n",
            "Collecting numpy==2.3.3 (from -r requirements_no_torch.txt (line 55))\n",
            "  Downloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: packaging==25.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 56)) (25.0)\n",
            "Collecting pandas==2.3.3 (from -r requirements_no_torch.txt (line 57))\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "Requirement already satisfied: parso==0.8.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 58)) (0.8.5)\n",
            "Requirement already satisfied: pexpect==4.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 59)) (4.9.0)\n",
            "Requirement already satisfied: pillow==11.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 60)) (11.3.0)\n",
            "Requirement already satisfied: platformdirs==4.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 61)) (4.5.0)\n",
            "Collecting polars==1.34.0 (from -r requirements_no_torch.txt (line 62))\n",
            "  Downloading polars-1.34.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting polars-runtime-32==1.34.0 (from -r requirements_no_torch.txt (line 63))\n",
            "  Downloading polars_runtime_32-1.34.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting portalocker==3.2.0 (from -r requirements_no_torch.txt (line 64))\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting propcache==0.4.1 (from -r requirements_no_torch.txt (line 65))\n",
            "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting protobuf==6.32.1 (from -r requirements_no_torch.txt (line 66))\n",
            "  Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting psutil==7.1.0 (from -r requirements_no_torch.txt (line 67))\n",
            "  Downloading psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 68)) (0.7.0)\n",
            "Collecting pure_eval==0.2.3 (from -r requirements_no_torch.txt (line 69))\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pyarrow==21.0.0 (from -r requirements_no_torch.txt (line 70))\n",
            "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting pydantic==2.12.0 (from -r requirements_no_torch.txt (line 71))\n",
            "  Downloading pydantic-2.12.0-py3-none-any.whl.metadata (83 kB)\n",
            "Collecting pydantic_core==2.41.1 (from -r requirements_no_torch.txt (line 72))\n",
            "  Downloading pydantic_core-2.41.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: Pygments==2.19.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 73)) (2.19.2)\n",
            "Requirement already satisfied: pyparsing==3.2.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 74)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 75)) (2.9.0.post0)\n",
            "Collecting pytorch-lightning==2.5.5 (from -r requirements_no_torch.txt (line 76))\n",
            "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting pytrec_eval-terrier==0.5.9 (from -r requirements_no_torch.txt (line 77))\n",
            "  Downloading pytrec_eval_terrier-0.5.9-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pytz==2025.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 78)) (2025.2)\n",
            "Requirement already satisfied: PyYAML==6.0.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 79)) (6.0.3)\n",
            "Collecting qdrant-client==1.15.1 (from -r requirements_no_torch.txt (line 80))\n",
            "  Downloading qdrant_client-1.15.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting regex==2025.9.18 (from -r requirements_no_torch.txt (line 81))\n",
            "  Downloading regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting requests==2.32.5 (from -r requirements_no_torch.txt (line 82))\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting rich==14.2.0 (from -r requirements_no_torch.txt (line 83))\n",
            "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: safetensors==0.6.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 84)) (0.6.2)\n",
            "Collecting scikit-learn==1.7.2 (from -r requirements_no_torch.txt (line 85))\n",
            "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: scipy==1.16.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 86)) (1.16.2)\n",
            "Requirement already satisfied: sentence-transformers==5.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 87)) (5.1.1)\n",
            "Requirement already satisfied: setuptools==80.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 88)) (80.9.0)\n",
            "Requirement already satisfied: simsimd==6.5.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 89)) (6.5.3)\n",
            "Requirement already satisfied: six==1.17.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 90)) (1.17.0)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 91)) (1.3.1)\n",
            "Collecting stack-data==0.6.3 (from -r requirements_no_torch.txt (line 92))\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: starlette==0.48.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 93)) (0.48.0)\n",
            "Collecting sympy==1.14.0 (from -r requirements_no_torch.txt (line 94))\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: threadpoolctl==3.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 95)) (3.6.0)\n",
            "Requirement already satisfied: tokenizers==0.22.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 96)) (0.22.1)\n",
            "Collecting torchmetrics==1.8.2 (from -r requirements_no_torch.txt (line 97))\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 98)) (4.67.1)\n",
            "Collecting traitlets==5.14.3 (from -r requirements_no_torch.txt (line 99))\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers==4.57.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 100)) (4.57.0)\n",
            "Requirement already satisfied: typing-inspection==0.4.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 101)) (0.4.2)\n",
            "Requirement already satisfied: typing_extensions==4.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 102)) (4.15.0)\n",
            "Requirement already satisfied: tzdata==2025.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 103)) (2025.2)\n",
            "Requirement already satisfied: urllib3==2.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 104)) (2.5.0)\n",
            "Collecting usearch==2.21.0 (from -r requirements_no_torch.txt (line 105))\n",
            "  Downloading usearch-2.21.0-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
            "Requirement already satisfied: uvicorn==0.37.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 106)) (0.37.0)\n",
            "Requirement already satisfied: wcwidth==0.2.14 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 107)) (0.2.14)\n",
            "Requirement already satisfied: xxhash==3.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 108)) (3.6.0)\n",
            "Requirement already satisfied: yarl==1.22.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_no_torch.txt (line 109)) (1.22.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.10.1->-r requirements_no_torch.txt (line 1)) (2.8.0+cu126)\n",
            "Requirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.12/dist-packages (from jupyter_client==8.6.3->-r requirements_no_torch.txt (line 40)) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.12/dist-packages (from jupyter_client==8.6.3->-r requirements_no_torch.txt (line 40)) (6.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.10.1->-r requirements_no_torch.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.10.1->-r requirements_no_torch.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.10.1->-r requirements_no_torch.txt (line 1)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.10.1->-r requirements_no_torch.txt (line 1)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.10.1->-r requirements_no_torch.txt (line 1)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.10.1->-r requirements_no_torch.txt (line 1)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.10.1->-r requirements_no_torch.txt (line 1)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.10.1->-r requirements_no_torch.txt (line 1)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.10.1->-r requirements_no_torch.txt (line 1)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.10.1->-r requirements_no_torch.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.10.1->-r requirements_no_torch.txt (line 1)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.10.1->-r requirements_no_torch.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.10.1->-r requirements_no_torch.txt (line 1)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.10.1->-r requirements_no_torch.txt (line 1)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.10.1->-r requirements_no_torch.txt (line 1)) (3.4.0)\n",
            "Downloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading comm-0.2.3-py3-none-any.whl (7.3 kB)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "Downloading debugpy-1.8.17-cp312-cp312-manylinux_2_34_x86_64.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
            "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
            "Downloading pydantic-2.12.0-py3-none-any.whl (459 kB)\n",
            "Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m193.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mteb-1.39.7-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m156.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading polars-1.34.0-py3-none-any.whl (772 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.7/772.7 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading polars_runtime_32-1.34.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
            "Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
            "Downloading psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (291 kB)\n",
            "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.41.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytrec_eval_terrier-0.5.9-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (304 kB)\n",
            "Downloading qdrant_client-1.15.1-py3-none-any.whl (337 kB)\n",
            "Downloading regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (802 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.0/802.0 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
            "Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m121.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "Downloading usearch-2.21.0-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pure_eval, traitlets, sympy, requests, regex, pydantic_core, pyarrow, psutil, protobuf, propcache, portalocker, polars-runtime-32, numpy, lightning-utilities, jedi, ipython_pygments_lexers, executing, eval_type_backport, decorator, debugpy, comm, asttokens, usearch, stack-data, rich, pydantic, polars, pandas, scikit-learn, pytrec_eval-terrier, matplotlib, jupyter_client, torchmetrics, qdrant-client, pytorch-lightning, datasets, mteb\n",
            "\u001b[2K  Attempting uninstall: traitlets\n",
            "\u001b[2K    Found existing installation: traitlets 5.7.1\n",
            "\u001b[2K    Uninstalling traitlets-5.7.1:\n",
            "\u001b[2K      Successfully uninstalled traitlets-5.7.1\n",
            "\u001b[2K  Attempting uninstall: sympy\n",
            "\u001b[2K    Found existing installation: sympy 1.13.3\n",
            "\u001b[2K    Uninstalling sympy-1.13.3:\n",
            "\u001b[2K      Successfully uninstalled sympy-1.13.3\n",
            "\u001b[2K  Attempting uninstall: requests\n",
            "\u001b[2K    Found existing installation: requests 2.32.4\n",
            "\u001b[2K    Uninstalling requests-2.32.4:\n",
            "\u001b[2K      Successfully uninstalled requests-2.32.4\n",
            "\u001b[2K  Attempting uninstall: regex\n",
            "\u001b[2K    Found existing installation: regex 2024.11.6\n",
            "\u001b[2K    Uninstalling regex-2024.11.6:\n",
            "\u001b[2K      Successfully uninstalled regex-2024.11.6\n",
            "\u001b[2K  Attempting uninstall: pydantic_core\n",
            "\u001b[2K    Found existing installation: pydantic_core 2.33.2\n",
            "\u001b[2K    Uninstalling pydantic_core-2.33.2:\n",
            "\u001b[2K      Successfully uninstalled pydantic_core-2.33.2\n",
            "\u001b[2K  Attempting uninstall: pyarrow\n",
            "\u001b[2K    Found existing installation: pyarrow 18.1.0\n",
            "\u001b[2K    Uninstalling pyarrow-18.1.0:\n",
            "\u001b[2K      Successfully uninstalled pyarrow-18.1.0\n",
            "\u001b[2K  Attempting uninstall: psutil\n",
            "\u001b[2K    Found existing installation: psutil 5.9.5\n",
            "\u001b[2K    Uninstalling psutil-5.9.5:\n",
            "\u001b[2K      Successfully uninstalled psutil-5.9.5\n",
            "\u001b[2K  Attempting uninstall: protobuf\n",
            "\u001b[2K    Found existing installation: protobuf 5.29.5\n",
            "\u001b[2K    Uninstalling protobuf-5.29.5:\n",
            "\u001b[2K      Successfully uninstalled protobuf-5.29.5\n",
            "\u001b[2K  Attempting uninstall: propcache\n",
            "\u001b[2K    Found existing installation: propcache 0.3.2\n",
            "\u001b[2K    Uninstalling propcache-0.3.2:\n",
            "\u001b[2K      Successfully uninstalled propcache-0.3.2\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 2.0.2\n",
            "\u001b[2K    Uninstalling numpy-2.0.2:\n",
            "\u001b[2K      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[2K  Attempting uninstall: decorator\n",
            "\u001b[2K    Found existing installation: decorator 4.4.2\n",
            "\u001b[2K    Uninstalling decorator-4.4.2:\n",
            "\u001b[2K      Successfully uninstalled decorator-4.4.2\n",
            "\u001b[2K  Attempting uninstall: debugpy\n",
            "\u001b[2K    Found existing installation: debugpy 1.8.15\n",
            "\u001b[2K    Uninstalling debugpy-1.8.15:\n",
            "\u001b[2K      Successfully uninstalled debugpy-1.8.15\n",
            "\u001b[2K  Attempting uninstall: rich\n",
            "\u001b[2K    Found existing installation: rich 13.9.4\n",
            "\u001b[2K    Uninstalling rich-13.9.4:\n",
            "\u001b[2K      Successfully uninstalled rich-13.9.4\n",
            "\u001b[2K  Attempting uninstall: pydantic\n",
            "\u001b[2K    Found existing installation: pydantic 2.11.10\n",
            "\u001b[2K    Uninstalling pydantic-2.11.10:\n",
            "\u001b[2K      Successfully uninstalled pydantic-2.11.10\n",
            "\u001b[2K  Attempting uninstall: polars\n",
            "\u001b[2K    Found existing installation: polars 1.25.2\n",
            "\u001b[2K    Uninstalling polars-1.25.2:\n",
            "\u001b[2K      Successfully uninstalled polars-1.25.2\n",
            "\u001b[2K  Attempting uninstall: pandas\n",
            "\u001b[2K    Found existing installation: pandas 2.2.2\n",
            "\u001b[2K    Uninstalling pandas-2.2.2:\n",
            "\u001b[2K      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[2K  Attempting uninstall: scikit-learn\n",
            "\u001b[2K    Found existing installation: scikit-learn 1.6.1\n",
            "\u001b[2K    Uninstalling scikit-learn-1.6.1:\n",
            "\u001b[2K      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[2K  Attempting uninstall: matplotlib\n",
            "\u001b[2K    Found existing installation: matplotlib 3.10.0\n",
            "\u001b[2K    Uninstalling matplotlib-3.10.0:\n",
            "\u001b[2K      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[2K  Attempting uninstall: jupyter_client\n",
            "\u001b[2K    Found existing installation: jupyter_client 7.4.9\n",
            "\u001b[2K    Uninstalling jupyter_client-7.4.9:\n",
            "\u001b[2K      Successfully uninstalled jupyter_client-7.4.9\n",
            "\u001b[2K  Attempting uninstall: datasets\n",
            "\u001b[2K    Found existing installation: datasets 4.0.0\n",
            "\u001b[2K    Uninstalling datasets-4.0.0:\n",
            "\u001b[2K      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/37\u001b[0m [mteb]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "gradio 5.49.0 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "notebook 6.5.7 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.3 which is incompatible.\n",
            "cudf-polars-cu12 25.6.0 requires polars<1.29,>=1.25, but you have polars 1.34.0 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.32.1 which is incompatible.\n",
            "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "bigframes 2.24.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.32.1 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.3 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.32.1 which is incompatible.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asttokens-3.0.0 comm-0.2.3 datasets-3.6.0 debugpy-1.8.17 decorator-5.2.1 eval_type_backport-0.2.2 executing-2.2.1 ipython_pygments_lexers-1.1.1 jedi-0.19.2 jupyter_client-8.6.3 lightning-utilities-0.15.2 matplotlib-3.10.7 mteb-1.39.7 numpy-2.3.3 pandas-2.3.3 polars-1.34.0 polars-runtime-32-1.34.0 portalocker-3.2.0 propcache-0.4.1 protobuf-6.32.1 psutil-7.1.0 pure_eval-0.2.3 pyarrow-21.0.0 pydantic-2.12.0 pydantic_core-2.41.1 pytorch-lightning-2.5.5 pytrec_eval-terrier-0.5.9 qdrant-client-1.15.1 regex-2025.9.18 requests-2.32.5 rich-14.2.0 scikit-learn-1.7.2 stack-data-0.6.3 sympy-1.14.0 torchmetrics-1.8.2 traitlets-5.14.3 usearch-2.21.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "debugpy",
                  "decorator",
                  "google",
                  "jupyter_client",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "psutil",
                  "traitlets"
                ]
              },
              "id": "e03cabddc73e430f9588f70c21310320"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seting up the Qdrant DB (parallel and backend)"
      ],
      "metadata": {
        "id": "tdFa4KcwMYSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean any old processes/logs\n",
        "!pkill -f qdrant || true\n",
        "!rm -f /content/qdrant.log\n",
        "\n",
        "# Download & unpack a Qdrant Linux binary\n",
        "!wget -qO /content/qdrant.tar.gz https://github.com/qdrant/qdrant/releases/download/v1.10.0/qdrant-x86_64-unknown-linux-gnu.tar.gz\n",
        "!tar -xzf /content/qdrant.tar.gz -C /content\n",
        "!chmod +x /content/qdrant\n",
        "\n",
        "# Make a storage dir (optional; Qdrant will default to ./storage anyway)\n",
        "!mkdir -p /content/storage\n",
        "\n",
        "# Start Qdrant (NO --storage flag). It will bind to 0.0.0.0:6333 and use ./storage.\n",
        "!nohup /content/qdrant --uri http://0.0.0.0:6333 > /content/qdrant.log 2>&1 &\n",
        "\n",
        "# Give it a second to boot\n",
        "import time; time.sleep(2)\n",
        "\n",
        "# Sanity checks\n",
        "!ps -ef | grep qdrant | grep -v grep || true\n",
        "!curl -s http://127.0.0.1:6333/ | head -n 5 || true\n",
        "\n",
        "# If curl didn't return JSON, print logs:\n",
        "!sed -n '1,200p' /content/qdrant.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTCZ8tOgBbqy",
        "outputId": "00a5848a-423e-45a0-ff39-39e0e4cc24ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "root        1046       1  1 17:51 ?        00:00:00 /content/qdrant --uri http://0.0.0.0:6333\n",
            "{\"title\":\"qdrant - vector search engine\",\"version\":\"1.10.0\",\"commit\":\"851f03bbf6644116da56f6bc7b0baa04274e8057\"}           _                 _    \n",
            "  __ _  __| |_ __ __ _ _ __ | |_  \n",
            " / _` |/ _` | '__/ _` | '_ \\| __| \n",
            "| (_| | (_| | | | (_| | | | | |_  \n",
            " \\__, |\\__,_|_|  \\__,_|_| |_|\\__| \n",
            "    |_|                           \n",
            "\n",
            "Version: 1.10.0, build: 851f03bb\n",
            "Access web UI at http://localhost:6333/dashboard\n",
            "\n",
            "2025-10-16T17:51:34.242154Z  WARN qdrant::settings: Config file not found: config/config    \n",
            "2025-10-16T17:51:34.242165Z  WARN qdrant::settings: Config file not found: config/development    \n",
            "2025-10-16T17:51:34.242204Z  INFO storage::content_manager::consensus::persistent: Initializing new raft state at ./storage/raft_state.json    \n",
            "2025-10-16T17:51:34.249524Z  INFO qdrant: Distributed mode disabled    \n",
            "2025-10-16T17:51:34.249546Z  INFO qdrant: Telemetry reporting enabled, id: 3d4b9f34-fe5e-4158-9a31-2ab1520b28d8    \n",
            "2025-10-16T17:51:34.251044Z  WARN qdrant::actix::web_ui: Static content folder for Web UI './static' does not exist    \n",
            "2025-10-16T17:51:34.251240Z  INFO qdrant::actix: TLS disabled for REST API    \n",
            "2025-10-16T17:51:34.251305Z  INFO qdrant::actix: Qdrant HTTP listening on 6333    \n",
            "2025-10-16T17:51:34.251316Z  INFO actix_server::builder: Starting 1 workers\n",
            "2025-10-16T17:51:34.251322Z  INFO actix_server::server: Actix runtime found; starting in Actix runtime\n",
            "2025-10-16T17:51:34.256127Z  INFO qdrant::tonic: Qdrant gRPC listening on 6334    \n",
            "2025-10-16T17:51:34.256146Z  INFO qdrant::tonic: TLS disabled for gRPC API    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate the baseline model"
      ],
      "metadata": {
        "id": "G7aRJS1-MeSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTHONPATH=/content:$PYTHONPATH\n",
        "\n",
        "!python scripts/evaluate.py \\\n",
        "    --model \"sentence-transformers/all-MiniLM-L12-v2\" \\\n",
        "    --qdrant-host \"127.0.0.1\" \\\n",
        "    --qdrant-port 6333 \\\n",
        "    --qdrant-collection \"cosqa_test_bodies\" \\\n",
        "    --K 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUQ-SksG5cwg",
        "outputId": "499d3e2e-5924-4d7f-c614-08ce1098099c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=/content:$PYTHONPATH\n",
            "2025-10-16 17:52:20.917519: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760637140.936926    1237 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760637140.942773    1237 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760637140.957595    1237 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760637140.957619    1237 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760637140.957622    1237 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760637140.957625    1237 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-16 17:52:20.962099: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "README.md: 2.33kB [00:00, 12.0MB/s]\n",
            "corpus/corpus-00000-of-00001.parquet: 100% 2.78M/2.78M [00:01<00:00, 2.04MB/s]\n",
            "Generating corpus split: 100% 20604/20604 [00:00<00:00, 628999.07 examples/s]\n",
            "queries/queries-00000-of-00001.parquet: 100% 592k/592k [00:00<00:00, 1.09MB/s]\n",
            "Generating queries split: 100% 20604/20604 [00:00<00:00, 993383.98 examples/s]\n",
            "[Info] Prepared test split: 500 corpus docs, 500 queries. Missing labels: 0\n",
            "modules.json: 100% 349/349 [00:00<00:00, 2.43MB/s]\n",
            "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 1.27MB/s]\n",
            "README.md: 10.5kB [00:00, 46.8MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 361kB/s]\n",
            "config.json: 100% 615/615 [00:00<00:00, 1.64MB/s]\n",
            "model.safetensors: 100% 133M/133M [00:01<00:00, 68.4MB/s]\n",
            "tokenizer_config.json: 100% 352/352 [00:00<00:00, 2.62MB/s]\n",
            "vocab.txt: 232kB [00:00, 113MB/s]\n",
            "tokenizer.json: 466kB [00:00, 142MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 764kB/s]\n",
            "config.json: 100% 190/190 [00:00<00:00, 1.77MB/s]\n",
            "Batches: 100% 8/8 [00:01<00:00,  5.49it/s]\n",
            "Batches: 100% 8/8 [00:00<00:00, 60.54it/s]\n",
            "[Timing] Encoded corpus in 1.47s, queries in 0.14s with sentence-transformers/all-MiniLM-L12-v2 (dim=384).\n",
            "/content/src/codesearch/eval/evaluator.py:74: UserWarning: Qdrant client version 1.15.1 is incompatible with server version 1.10.0. Major versions should match and minor version difference must not exceed 1. Set check_compatibility=False to skip version check.\n",
            "  client = QdrantClient(host=args.qdrant_host, port=args.qdrant_port)\n",
            "[Index] Upserted 500 vectors into Qdrant collection 'cosqa_test_bodies' at 127.0.0.1:6333\n",
            "\n",
            "=== CoSQA (test) — Qdrant Retrieval Metrics ===\n",
            "Model: sentence-transformers/all-MiniLM-L12-v2\n",
            "K: 3\n",
            "Recall@3: 0.8960\n",
            "MRR@3:    0.7850\n",
            "nDCG@3:   0.8137\n",
            "(Retrieval time for 500 queries: 1.13s)\n",
            "\n",
            "--- Sample retrieved doc_ids for first few queries ---\n",
            "Query q20105 -> hits: [(0, 'd20105'), (225, 'd20330'), (317, 'd20422'), (320, 'd20425'), (12, 'd20117')] ; relevant: [0]\n",
            "Query q20106 -> hits: [(1, 'd20106'), (377, 'd20482'), (25, 'd20130'), (237, 'd20342'), (487, 'd20592')] ; relevant: [1]\n",
            "Query q20107 -> hits: [(224, 'd20329'), (2, 'd20107'), (279, 'd20384'), (31, 'd20136'), (448, 'd20553')] ; relevant: [2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning of the baseline model"
      ],
      "metadata": {
        "id": "vpNrqxZ0MiRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/train.py \\\n",
        "    --model \"sentence-transformers/all-MiniLM-L12-v2\" \\\n",
        "    --finetune-dir \"./models\" \\\n",
        "    --checkpoint-path \"./checkpoint\" \\\n",
        "    --assets-dir \"./results/assets\" \\\n",
        "    --qdrant-host \"qdrant\" \\\n",
        "    --qdrant-port 6333 \\\n",
        "    --qdrant-collection \"cosqa_test_bodies\" \\\n",
        "    --qdrant-collection-ft \"cosqa_test_ft\" \\\n",
        "    --K 10 \\\n",
        "    --batch-size 32 \\\n",
        "    --epochs 10 \\\n",
        "    --lr 2e-5 \\\n",
        "    --max-steps-per-epoch 0 \\\n",
        "    --seed 69"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNO1rdfC6BNr",
        "outputId": "ac0d041c-e8c4-446c-f15e-a9bfbc12f5d6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-16 17:55:07.743954: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760637307.763991    2141 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760637307.769833    2141 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760637307.784798    2141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760637307.784822    2141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760637307.784826    2141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760637307.784829    2141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-16 17:55:07.789207: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "[Data] Train: 19604 q / 19604 docs\n",
            "\n",
            "[Train] Fine-tuning with MultipleNegativesRankingLoss (in-batch negatives)…\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Create a W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Create an account here: https://wandb.ai/authorize?signup=true&ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maleks-raudit\u001b[0m (\u001b[33maleks-raudit-university-of-amsterdam\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m setting up run y53qrsku (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m setting up run y53qrsku (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m setting up run y53qrsku (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20251016_175709-y53qrsku\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33micy-cherry-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aleks-raudit-university-of-amsterdam/sentence-transformers\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aleks-raudit-university-of-amsterdam/sentence-transformers/runs/y53qrsku\u001b[0m\n",
            "{'loss': 0.1633, 'grad_norm': 5.771317005157471, 'learning_rate': 1.6307189542483662e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0963, 'grad_norm': 1.6076011657714844, 'learning_rate': 1.859840232389252e-05, 'epoch': 1.63}\n",
            "{'loss': 0.0737, 'grad_norm': 3.829636335372925, 'learning_rate': 1.6782861292665216e-05, 'epoch': 2.45}\n",
            " 29% 1763/6120 [03:36<08:14,  8.81it/s]\n",
            "{'loss': 0.061, 'grad_norm': 0.9986067414283752, 'learning_rate': 1.496732026143791e-05, 'epoch': 3.27}\n",
            "{'loss': 0.0555, 'grad_norm': 0.9696615934371948, 'learning_rate': 1.3151779230210603e-05, 'epoch': 4.08}\n",
            "{'loss': 0.0495, 'grad_norm': 2.2952048778533936, 'learning_rate': 1.1336238198983298e-05, 'epoch': 4.9}\n",
            "{'loss': 0.0418, 'grad_norm': 2.9469103813171387, 'learning_rate': 9.520697167755992e-06, 'epoch': 5.72}\n",
            "{'loss': 0.0417, 'grad_norm': 2.076686382293701, 'learning_rate': 7.705156136528687e-06, 'epoch': 6.54}\n",
            "{'loss': 0.0377, 'grad_norm': 2.0867247581481934, 'learning_rate': 5.889615105301381e-06, 'epoch': 7.35}\n",
            "{'loss': 0.0356, 'grad_norm': 0.9683251976966858, 'learning_rate': 4.074074074074074e-06, 'epoch': 8.17}\n",
            "{'loss': 0.036, 'grad_norm': 2.783633232116699, 'learning_rate': 2.2585330428467685e-06, 'epoch': 8.99}\n",
            "{'loss': 0.032, 'grad_norm': 2.1421308517456055, 'learning_rate': 4.4299201161946263e-07, 'epoch': 9.8}\n",
            "{'train_runtime': 873.3163, 'train_samples_per_second': 224.249, 'train_steps_per_second': 7.008, 'train_loss': 0.05990567316416821, 'epoch': 10.0}\n",
            "100% 6120/6120 [12:48<00:00,  7.97it/s]\n",
            "[Save] Finetuned model saved to: ../models\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/scripts/train.py\", line 5, in <module>\n",
            "    main()\n",
            "  File \"/content/src/codesearch/train/trainer.py\", line 110, in main\n",
            "    plt.savefig(out_png, bbox_inches=\"tight\")\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/matplotlib/pyplot.py\", line 1250, in savefig\n",
            "    res = fig.savefig(*args, **kwargs)  # type: ignore[func-returns-value]\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/matplotlib/figure.py\", line 3490, in savefig\n",
            "    self.canvas.print_figure(fname, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/matplotlib/backend_bases.py\", line 2186, in print_figure\n",
            "    result = print_method(\n",
            "             ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/matplotlib/backend_bases.py\", line 2042, in <lambda>\n",
            "    print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(\n",
            "                                                                 ^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/matplotlib/backends/backend_agg.py\", line 481, in print_png\n",
            "    self._print_pil(filename_or_obj, \"png\", pil_kwargs, metadata)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/matplotlib/backends/backend_agg.py\", line 430, in _print_pil\n",
            "    mpl.image.imsave(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/matplotlib/image.py\", line 1657, in imsave\n",
            "    image.save(fname, **pil_kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/Image.py\", line 2583, in save\n",
            "    fp = builtins.open(filename, \"w+b\")\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '../results/assets/train_loss_curve.png'\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33micy-cherry-1\u001b[0m at: \u001b[34m\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251016_175709-y53qrsku/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final evaluation of fine-tuned model"
      ],
      "metadata": {
        "id": "EOJX-JobMncu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/evaluate.py \\\n",
        "    --model \"../models\" \\\n",
        "    --qdrant-host \"127.0.0.1\" \\\n",
        "    --qdrant-port 6333 \\\n",
        "    --qdrant-collection \"cosqa_test_bodies\" \\\n",
        "    --K 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHnpBQZ96Dh1",
        "outputId": "fbe0e424-23ed-4823-c429-e0115a0908a0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-16 18:14:03.411031: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760638443.442029    7233 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760638443.451495    7233 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760638443.473963    7233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760638443.473990    7233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760638443.473998    7233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760638443.474005    7233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-16 18:14:03.480477: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "[Info] Prepared test split: 500 corpus docs, 500 queries. Missing labels: 0\n",
            "Batches: 100% 8/8 [00:01<00:00,  6.18it/s]\n",
            "Batches: 100% 8/8 [00:00<00:00, 53.19it/s]\n",
            "[Timing] Encoded corpus in 1.31s, queries in 0.16s with ../models (dim=384).\n",
            "/content/src/codesearch/eval/evaluator.py:74: UserWarning: Qdrant client version 1.15.1 is incompatible with server version 1.10.0. Major versions should match and minor version difference must not exceed 1. Set check_compatibility=False to skip version check.\n",
            "  client = QdrantClient(host=args.qdrant_host, port=args.qdrant_port)\n",
            "[Index] Upserted 500 vectors into Qdrant collection 'cosqa_test_bodies' at 127.0.0.1:6333\n",
            "\n",
            "=== CoSQA (test) — Qdrant Retrieval Metrics ===\n",
            "Model: ../models\n",
            "K: 3\n",
            "Recall@3: 0.9720\n",
            "MRR@3:    0.8843\n",
            "nDCG@3:   0.9070\n",
            "(Retrieval time for 500 queries: 1.26s)\n",
            "\n",
            "--- Sample retrieved doc_ids for first few queries ---\n",
            "Query q20105 -> hits: [(0, 'd20105'), (12, 'd20117'), (225, 'd20330'), (163, 'd20268'), (317, 'd20422')] ; relevant: [0]\n",
            "Query q20106 -> hits: [(1, 'd20106'), (377, 'd20482'), (25, 'd20130'), (80, 'd20185'), (60, 'd20165')] ; relevant: [1]\n",
            "Query q20107 -> hits: [(2, 'd20107'), (224, 'd20329'), (185, 'd20290'), (51, 'd20156'), (83, 'd20188')] ; relevant: [2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving of model"
      ],
      "metadata": {
        "id": "ZpgQeLVHPAX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_folder(\"../models\", \"./models.zip\")"
      ],
      "metadata": {
        "id": "OTMOgFxOPEcd"
      },
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}