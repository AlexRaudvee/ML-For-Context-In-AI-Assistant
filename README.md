
# ğŸ” Embeddings-based Code Search (CoSQA) â€” Endâ€‘toâ€‘End

This repository implements a simple but complete **code search engine** with:
- **Indexing** code into a **Qdrant** vector database
- **FastAPI** search API
- **Evaluation on CoSQA** (test partition): **Recall@K, MRR@K, nDCG@K**
- **Fineâ€‘tuning** a biâ€‘encoder on CoSQA (train) and showing improved test metrics
- **Smart chunking** (Python functions/classes via AST; windowed fallback for other langs)
- **Dev Containers** + `docker-compose` for a oneâ€‘command local stack

> âš ï¸ Note: Model weights in some folders were deleted to keep this repo light. The code will download base models automatically; fineâ€‘tuned checkpoints will be saved to `models/` during training.

---

## ğŸ§­ Quick Start (TL;DR)

```bash
# 0) Bring up Qdrant + dev container (from repo root on host)
docker compose up -d

# 1) (Optional) Open in VS Code -> "Reopen in Container"
#    or attach a shell into the app container:
docker compose exec app bash

# 2) Install Python deps (inside container)
pip install -r requirements.txt

# 3) Ingest your codebase into Qdrant (smart chunking)
python scripts/ingest.py \
  --input_glob "data/examples/**/*.py" \
  --model sentence-transformers/all-MiniLM-L12-v2 \
  --qdrant-host qdrant --qdrant-port 6333 \
  --qdrant-collection codes --qdrant-recreate \
  --include-comments --max-func-lines 180 --win-lines 120 --overlap-lines 30

# 4) (Optional) Run the search API
python scripts/serve_api.py \
  --backend qdrant \
  --model sentence-transformers/all-MiniLM-L12-v2 \
  --qdrant-host qdrant --qdrant-port 6333 \
  --qdrant-collection codes

# 5) Evaluate on CoSQA (test) with any model or local finetuned dir
python -m codesearch.eval.evaluator \
  --model sentence-transformers/all-MiniLM-L12-v2 \
  --qdrant-host qdrant --qdrant-port 6333 \
  --qdrant-collection cosqa_test_baseline \
  --K 10
```

---

## ğŸ³ Dev Environment (Docker & VS Code)

### Compose stack
The repo ships with `docker-compose.yml` that defines:
- `qdrant` â€” the vector DB (ports **6333/REST**, **6334/gRPC** exposed to host)
- `app` â€” your Python dev container with the repo bindâ€‘mounted at `/workspace`

Start both:
```bash
docker compose up -d
docker compose ps
```

Open the Qdrant UI / REST endpoint at: `http://localhost:6333`

### VS Code Dev Container (recommended)
- `.devcontainer/Dockerfile` builds the dev image (Python 3.12, sets `PYHYONPATH=/workspace/src`).
- `.devcontainer/devcontainer.json` attaches VS Code to the `app` service from compose.

Steps:
1. Open repo in VS Code
2. **Command Palette â†’ Dev Containers: Reopen in Container**
3. A terminal opens inside `/workspace` with all ports forwarded (8000 for API, 6333 for Qdrant).

---

## ğŸ“ Directory Structure

```
.
â”œâ”€â”€ .devcontainer/                 # VS Code dev container config
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ devcontainer.json
â”œâ”€â”€ google-colab/                  # Google colab version for fine-tuning of the model
â”‚   â”œâ”€â”€ main.ipynb
â”‚   â””â”€â”€ ziped version 
â”œâ”€â”€ docker-compose.yml             # Brings up qdrant + app
â”œâ”€â”€ dockerfile                     # (lowercase) optional standalone build
â”œâ”€â”€ requirements.txt               # Python deps
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ how-to-run.ipynb           # runnable demo / report notebook
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ingest.py                  # Chunk -> embed -> upsert to Qdrant
â”‚   â”œâ”€â”€ serve_api.py               # FastAPI server (Qdrant backend)
â”‚   â””â”€â”€ train.py                   # Fine-tune + plots + test eval
â”œâ”€â”€ src/codesearch/
â”‚   â”œâ”€â”€ api/main.py                # FastAPI app (/search): encodes query, queries Qdrant
â”‚   â”œâ”€â”€ embeddings.py              # SentenceTransformers wrapper
â”‚   â”œâ”€â”€ index/
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â””â”€â”€ qdrant_index.py        # Qdrant adapter
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ chunkers.py            # Python AST chunker + line-window fallback
â”‚   â”‚   â”œâ”€â”€ eval.py                # dataset helpers (pick_text, id mapping, etc.)
â”‚   â”‚   â””â”€â”€ logging.py
â”‚   â”œâ”€â”€ metrics/ranking.py         # Recall@K, MRR@K, nDCG@K (binary)
â”‚   â”œâ”€â”€ eval/evaluator.py          # CoSQA test eval via Qdrant
â”‚   â””â”€â”€ train/                     # Fine-tuning utilities
â”‚       â”œâ”€â”€ trainer.py             # CLI: builds train pairs, trains MNRL, plots loss
â”‚       â””â”€â”€ losses.py              # InfoNCE, MNRL, and loggers
â”œâ”€â”€ data/                          # Sample code (gitignored except placeholders)
â”œâ”€â”€ models/                        # Saved checkpoints (youâ€™ll populate)
â”œâ”€â”€ results/                       # Metrics, plots (created by scripts)
â”œâ”€â”€ qdrant_storage/                # Qdrant persistent storage (volume)
â””â”€â”€ README.md                      # (this file)
```

---

## ğŸ§© Part 1 â€” Index & Search (Qdrant)

### Smart chunking
`src/codesearch/utils/chunkers.py`:
- **Python**: splits by **functions/classes** via `ast`. Long defs are windowed (e.g., 120 lines with 30â€‘line overlap). Prepends leading `#` comments for context.
- **Others**: lineâ€‘window fallback with overlap.
- Each chunk gets payload: `{{path, lang, kind, symbol, start_line, end_line, part, n_parts}}`.

### Ingest into Qdrant
```bash
python scripts/ingest.py   --input_glob "data/examples/**/*.py"   --model sentence-transformers/all-MiniLM-L12-v2   --qdrant-host qdrant --qdrant-port 6333   --qdrant-collection codes --qdrant-recreate   --include-comments --max-func-lines 180 --win-lines 120 --overlap-lines 30
```

### Serve API
```bash
python scripts/serve_api.py   --backend qdrant   --model sentence-transformers/all-MiniLM-L12-v2   --qdrant-host qdrant --qdrant-port 6333   --qdrant-collection codes
```
### Query:
```bash
curl -X POST "http://localhost:8000/search"   -H "Content-Type: application/json"   -d '{{"query":"read csv with pandas", "k":5, "lang":"python"}}'
```

---

## ğŸ§ª Part 2 â€” Evaluation on CoSQA (test)

The evaluator builds a **Qdrant** index from **CoSQA corpus (test)** and retrieves for **CoSQA queries (test)**. Relevance is matched by id suffix (**qNN â†” dNN**).

Run:
```bash
python -m codesearch.eval.evaluator   --model sentence-transformers/all-MiniLM-L12-v2   --qdrant-host qdrant --qdrant-port 6333   --qdrant-collection cosqa_test_baseline   --K 10
```

It prints:
- `Recall@K` â€” fraction of queries with at least one relevant doc in topâ€‘K
- `MRR@K` â€” reciprocal rank (positionâ€‘sensitive)
- `nDCG@K` â€” positionâ€‘sensitive with ideal DCG normalization

> Metrics code: `src/codesearch/metrics/ranking.py`

---

## ğŸ”§ Part 3 â€” Fineâ€‘tuning (CoSQA train â†’ test)

Train a biâ€‘encoder with **MultipleNegativesRankingLoss** (inâ€‘batch negatives). The trainer also saves a **training loss curve**.

```bash
python scripts/train.py   --finetune-dir models/cosqa-biencoder   --checkpoint-path checkpoint   --assets-dir results/assets   --batch-size 64 --epochs 1 --lr 2e-5   --qdrant-host qdrant --qdrant-port 6333   --qdrant-collection cosqa_test_bodies   --qdrant-collection-ft cosqa_test_ft   --K 10
```

What it does:
1. Loads **CoSQA train** (queries â†” corpus by `qNN â†” dNN`) to create `(query, positive_code)` pairs.
2. Trains with **MNRL**.
3. Records **training loss** (per batch or downsampled) and saves plot to `results/assets/`.
4. Saves the model in `models` folder

Reâ€‘evaluate finetuned model (no code changes to evaluator):
```bash
python -m codesearch.eval.evaluator   --model models/cosqa-biencoder   --qdrant-host qdrant --qdrant-port 6333   --qdrant-collection cosqa_test_finetuned   --K 10
```

---

## ğŸ““ Notebook

`notebooks/how-to-run.ipynb` shows the endâ€‘toâ€‘end flow. To run it **inside the dev container**:

1. With the stack up (`docker compose up -d`) and VS Code attached, open the notebook.
2. Select the Python kernel inside the container.
3. Ensure Qdrant is up (visit http://localhost:6333).

If running via CLI:
```bash
docker compose exec app bash -lc "jupyter nbconvert --to notebook --execute notebooks/how-to-run.ipynb --inplace"
```

## Google Colab 

`main.ipynb` is the main file that you have to run in colab. At the same time do not forget to load the ziped version of repo (given in `google-colab` folder) in your google disk (the account that you use for colab and disk should be the same).

---

## ğŸ“Š Results

### Table with Results
| Model                                      | Recall@10 | MRR@10 | nDCG@10 |
|-------------------------------------------|-----------|--------|---------|
| `all-MiniLM-L12-v2` (baseline)            |0.9780|0.8017|0.8456|
| `cosqa-biencoder` (finetuned, +epochs)    |0.9960|0.8877|0.9152|

> Note: In general we can see a good improvement of results 

- **Training loss curve**: see `results/assets`
- **GPU and Disk usage**: see `results/assets`

- **Example**: Before fine-tunning

```
Query q20105 -> hits: [(0, 'd20105'), (225, 'd20330'), (317, 'd20422'), (320, 'd20425'), (12, 'd20117')] ; relevant: [0]
Query q20106 -> hits: [(1, 'd20106'), (377, 'd20482'), (25, 'd20130'), (237, 'd20342'), (487, 'd20592')] ; relevant: [1]
Query q20107 -> hits: [(224, 'd20329'), (2, 'd20107'), (279, 'd20384'), (31, 'd20136'), (448, 'd20553')] ; relevant: [2]
```

- **Example**: After fine-tunning

```
Query q20105 -> hits: [(0, 'd20105'), (12, 'd20117'), (225, 'd20330'), (163, 'd20268'), (317, 'd20422')] ; relevant: [0]
Query q20106 -> hits: [(1, 'd20106'), (377, 'd20482'), (25, 'd20130'), (80, 'd20185'), (60, 'd20165')] ; relevant: [1]
Query q20107 -> hits: [(2, 'd20107'), (224, 'd20329'), (185, 'd20290'), (51, 'd20156'), (83, 'd20188')] ; relevant: [2]
```

### Visuals


<p align="center">
  <img src="results/assets/train_loss.png" alt="Training loss curve" width="48%">
  <img src="results/assets/lr_rate.png" alt="Training LR rate" width="48%">
</p>


<p align="center">
  <img src="results/assets/gpu_utilization.png" alt="GPU Utilization" width="48%">
  <img src="results/assets/disk_utilization.png" alt="Disk Utilization" width="48%">
</p>


---

## ğŸ—£ Discussion

- All three metrics improvedâ€”Recall@10: 0.9780 â†’ 0.9960, MRR@10: 0.8017 â†’ 0.8877, nDCG@10: 0.8456 â†’ 0.9152â€”so the model both finds the right code more often and ranks it higher. This is exactly what MultipleNegativesRankingLoss tends to deliver: tighter alignment of queryâ†”code positives and stronger separation from in-batch negatives, which boosts top-rank precision (MRR/nDCG) while also broadening coverage (Recall) when the domain matches the fine-tuning data.

---

## ğŸ§¯ Troubleshooting

- **`qdrant` hostname not found**: ensure you run via `docker-compose` and VS Code attaches to the **app** service in the same network.
- **Dimension mismatch**: delete/recreate collection when switching encoders.
- **No loss plotted**: check the training script flags; confirm the logger/evaluator is enabled.

---

## ğŸ“„ License

See [`LICENSE`](LICENSE).

---

## ğŸ™ Acknowledgements

- [Sentence-Transformers](https://www.sbert.net/)
- [Qdrant](https://qdrant.tech/)
- CoSQA via [Hugging Face Datasets](https://huggingface.co/datasets/CoIR-Retrieval/cosqa)
